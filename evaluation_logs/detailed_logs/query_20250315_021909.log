DETAILED QUERY LOG - 2025-03-15 02:19:09
======================================================================

QUESTION: How do I inform Vitess of a new primary tablet after a manual failover?

ANSWER: ### Informing Vitess of a New Primary Tablet After Manual Failover
To inform Vitess of a new primary tablet after a manual failover, you need to use the `TabletExternallyReparented` command. This command updates Vitess with the new primary tablet for a shard, ensuring that writes are routed correctly and do not fail due to being sent to a read-only replica (the old primary).

#### Steps to Inform Vitess:
1. **Identify the New Primary Tablet**: Ensure you know the identity of the new primary tablet that has taken over after the manual failover.
2. **Use the `TabletExternallyReparented` Command**: Execute the `TabletExternallyReparented` command, specifying the new primary tablet for the shard. This command is part of the `vtctl` tool, which is used for managing Vitess.

Example:
```bash
vtctl TabletExternallyReparented <shard> <new_primary_tablet>
```
Replace `<shard>` with the name of the shard that the new primary tablet belongs to, and `<new_primary_tablet>` with the alias of the new primary tablet.

#### Additional Considerations:
- **Older Versions of Vitess**: In older versions of Vitess, tools like Orchestrator can be configured to automatically call `TabletExternallyReparented` when a failover occurs, streamlining the process.
- **Sample Configuration**: For reference, a sample `orchestrator.conf.json` file can be found in the Vitess repository, demonstrating how to configure Orchestrator for automatic failover handling.

By following these steps and using the `TabletExternallyReparented` command, you can ensure that Vitess is aware of the new primary tablet after a manual failover, maintaining the integrity and functionality of your database cluster.

METRICS:
  - Documents Retrieved: 3
  - Top Document Score: 0.9980881810188293
  - Response Time: 23046.51 ms
  - Retrieval Time (est.): 16132.55 ms

RETRIEVED DOCUMENTS:
Document 1:
  Source: Unknown
  Score: 0.9980881810188293
  Content:
----------------------------------------
cause. It could be network issues, or it could be a recent change in app behavior. Diagnosis 4: No particular transaction seems to be the culprit. Nothing seems to have changed in any of the requests. Look at system variables to see if there are hardware faults. Is the disk latency too high? Are there memory parity errors? If so, you may have to failover to a new machine. --- title: Primary starts up read-only description: Debug common issues with Vitess weight: 5 --- ## Primary starts up read-only To prevent accidentally accepting writes, our default my.cnf settings tell MySQL to always start up read-only. If the primary MySQL gets restarted, it will thus come back read-only until someone intervene to confirm that it should accept writes. If VTOrc is running, then it will take care of converting the primary to read-write mode. However, to fix manually, you can use the [`SetReadWrite`](../../reference/programs/vtctl/tablets/#setreadwrite) command to do that. Usually if something unexpected happens to the primary, it's better to reparent to a different replica with [`EmergencyReparentShard`](../../reference/programs/vtctl/shards/#emergencyreparentshard). If you need to do planned maintenance on the primary, it's best to first reparent to another replica with [`PlannedReparentShard`](../../reference/programs/vtctl/shards/#plannedreparentshard). --- title: Vitess sees the wrong tablet as primary description: Debug common issues with Vitess weight: 10 --- ## Vitess sees the wrong tablet as primary If you do a failover manually (not through Vitess), you'll need to tell Vitess which tablet corresponds to the new primary MySQL. Until then, writes will fail since they'll be routed to a read-only replica (the old primary). Use the [`TabletExternallyReparented`](../../reference/programs/vtctl/shards/#tabletexternallyreparented) command to tell Vitess the new primary tablet for a shard. Older versions of Vitess supported tools like [Orchestrator](https://github.com/github/orchestrator), which can be configured to call this automatically when a failover occurs. See our sample [orchestrator.conf.json](https://github.com/vitessio/vitess/blob/1129d69282bb738c94b8af661b984b6377a759f7/docker/orchestrator/orchestrator.conf.json#L131) for an example of 
----------------------------------------

Document 2:
  Source: Unknown
  Score: 0.9864112734794617
  Content:
----------------------------------------
above, we introduced the schema tracker, which could be running on the VTTablets now. You can disable it in order to prevent that reporting. You will need to add `track_schema_versions` as false in the VTTablet. ## What are the steps to take after an unplanned failover? In order to avoid creating orphaned VTTablets you will need to follow the steps below: 1. Stop the VTTablets 2. Delete the old VTTablet records 3. Create the new keyspace 4. Restart the VTTablets that are pointed at the new keyspace 5. Use TabletExternallyReparented to inform Vitess of the current primary 6. Recursively delete the old keyspace ## Error: Could not open required defaults file: /path/to/my.cnf If you cannot start a cluster and see that error in the logs it most likely means that AppArmor is running on your server and is preventing Vitess processes from accessing the my.cnf file. The workaround is to uninstall AppArmor: ```sh sudo service apparmor stop sudo service apparmor teardown sudo update-rc.d -f apparmor remove ``` You may also need to reboot the machine after this. Many programs automatically install AppArmor, so you may need to uninstall again. ## Error: mysqld not found in any of /usr/bin/{sbin,bin,libexec} If you're all set up with Vitess but mysqld won't start, with an error like this: ```sh E0430 17:02:43.663441 5297 mysqlctl.go:254] failed start mysql: mysqld not found in any of /usr/bin/{sbin,bin,libexec} ``` You will need to perform the following steps: - Verify that mysqld is located in /usr/bin on all its hosts - Verify that PATH has been set and sourced in .bashrc If you have confirmed the above and are still getting the error referenced, it is likely that `VT_MYSQL_ROOT` has not been set correctly. On most systems `VT_MYSQL_ROOT` should be set to `/usr` because Vitess expects to find a bin 
----------------------------------------

Document 3:
  Source: Unknown
  Score: 0.9651528000831604
  Content:
----------------------------------------
(`vtgate`) whether Online DDL operations are at all possible through `VTGate`. Type: boolean. Default: `true` Example: `vtgate --enable_online_ddl=false` to disable access to Online DDL via `VTGate`. ## Auto resume after failure VReplication based migrations (`ddl_strategy="vitess"`) are [failover agnostic](../recoverable-migrations/). They automatically resume after either planned promotion ([PlannedReparentShard](../../configuration-advanced/reparenting/#plannedreparentshard-planned-reparenting)), emergency promotion ([EmergencyReparentShard](../../configuration-advanced/reparenting/#emergencyreparentshard-emergency-reparenting)) or completely external reparenting. Once the new primary is in place and turns active, it auto-resumes the VReplication stream. The online DDL scheduler assumes ownership of the stream and follows it to completion. The new primary must be available within `10 minutes`, or else the migration is considered to be stale and is aborted. ## Auto retry after failure Vitess management can issue an automated retry (starting the migration afresh). - which `vttablet` initiated the migration - how many times a migration has been retried - whether a migration failed due to a `vttablet` failure (as is the case in a failover scenario) Vitess will auto-retry a failed migration when: - The migration failed due to a `vttablet` failure, and - it has not been retried (this is a temporary restriction) The migration will be transitioned into `queued` state, as if the user requested a `retry` operation. Note that this takes place on a per-shard basis. The primary use case is a primary failure and failover. The newly promoted tablet will be able to retry the migration that broke during the previous primary failure. To clarify, the migration will start anew, as at this time there is no mechanism to resume a broken migration. ## Throttling `vitess` utilizes the tablet throttler, which is a cooperative throttler service based on replication lag. The tablet throttler automatically detects topology `REPLICA` tablets and adapts to changes in the topology. See [Tablet throttler](../../../reference/features/tablet-throttler/). **NOTE** that at this time (and subject to change) the tablet throttler 
----------------------------------------

