DETAILED QUERY LOG - 2025-03-16 20:23:21
======================================================================

QUESTION: How does Vitess handle distributed transactions, and what are the trade-offs of using Two-Phase Commit (TwoPC)?

ANSWER: ### Distributed Transactions in Vitess
Vitess handles distributed transactions through its support for multi-db transactions. It provides three levels of atomicity:
* `SINGLE`: disallows multi-db transactions
* `MULTI`: allows multi-db transactions with best effort commit
* `TWOPC`: allows multi-db transactions with 2PC (Two-Phase Commit) commit

### Two-Phase Commit (TwoPC) in Vitess
TwoPC is a protocol used to ensure atomicity in distributed transactions. In Vitess, TwoPC is used to commit transactions that span multiple databases. The process involves two phases:
1. **Prepare phase**: The transaction is prepared on all participating databases.
2. **Commit phase**: If all databases agree to commit, the transaction is committed; otherwise, it is rolled back.

### Trade-offs of Using TwoPC
The trade-offs of using TwoPC in Vitess are:
* **Increased latency**: TwoPC introduces additional latency due to the extra round-trip required for the prepare and commit phases.
* **Increased complexity**: TwoPC adds complexity to the transaction management process, which can lead to increased error rates and debugging challenges.
* **Lock contention**: TwoPC can lead to lock contention, as multiple transactions may be competing for locks on the same resources.

However, TwoPC provides strong consistency guarantees, ensuring that transactions are atomic and durable, even in the presence of failures. This makes it a suitable choice for applications that require high levels of consistency and reliability.

### When to Use TwoPC
TwoPC is suitable for use cases that require:
* **Strong consistency**: Applications that require strict consistency guarantees, such as financial transactions or critical system updates.
* **High availability**: Applications that require high availability and can tolerate the additional latency introduced by TwoPC.
* **Distributed transactions**: Applications that involve multiple databases or services, and require atomicity across these components.

In summary, Vitess's support for TwoPC provides a robust mechanism for handling distributed transactions, but it comes with trade-offs in terms of latency, complexity, and lock contention. The choice to use TwoPC should be based on the specific requirements of the application and the trade-offs that are acceptable.

METRICS:
  - Documents Retrieved: 4
  - Top Document Score: 0.7933860421180725
  - Response Time: 21103.27 ms

RETRIEVED DOCUMENTS:
Document 1:
  Source: Unknown
  Score: 0.7933860421180725
  Content:
----------------------------------------
servers are capable of monitoring replica lag and can be configured to avoid serving data from instances that are lagging beyond X seconds. For a true snapshot, queries must be sent to the primary within a transaction. For read-after-write consistency, reading from the primary without a transaction is sufficient. To summarize, these are the various levels of consistency supported: * `REPLICA/RDONLY` read: Servers can be scaled geographically. Local reads are fast, but can be stale depending on replica lag. * `PRIMARY` read: There is only one worldwide primary per shard. Reads coming from remote locations will be subject to network latency and reliability, but the data will be up-to-date (read-after-write consistency). The isolation level is `READ_COMMITTED`. * `PRIMARY` transactions: These exhibit the same properties as PRIMARY reads. However, you get REPEATABLE_READ consistency and ACID writes for a single shard. Support is planned for cross-shard Atomic transactions. As for atomicity, the following levels are supported: * `SINGLE`: disallow multi-db transactions. * `MULTI`: multi-db transactions with best effort commit. * `TWOPC`: multi-db transactions with 2PC commit. ### No active-active replication Vitess doesn’t support active-active replication setup (previously called multi-master). It has alternate ways of addressing most of the use cases that are typically solved by such a configuration. * Scalability: There are situations where active-active gives you a little bit of additional runway. However, since all writes have to eventually be applied to all writable servers, it’s not a sustainable strategy. Vitess addresses this problem through sharding, which can scale indefinitely. * High availability: Vitess has native capability for detecting primary failures and performing a failover to a new primary within seconds of failure detection. This is usually sufficient for most applications. * Low-latency geographically distributed writes: This is one case that is not addressed by Vitess. The current recommendation is to absorb the latency cost of long-distance round-trips for writes. If the data distribution allows, you still have the option of sharding based on geographic affinity. You can then setup primaries for different shards to be in different geographic locations. This way, most of the primary writes can still be local. ## Multi-cell Vitess is meant to run in multiple data centers / regions / cells. In this part, we'll use "cell" to mean a set of servers that are very close together, and share the same regional availability. A cell typically contains a set of tablets, a vtgate pool, and app servers that use the Vitess cluster. With Vitess, all components can be configured and brought up as needed: * The primary for a shard can be in any cell. If cross-cell primary access is required, vtgate can be configured to do so easily (by passing the cell that contains the primary as a cell to watch). * It is not uncommon to have the cells that can contain the primary be more provisioned than read-only serving cells. These *primary-capable* cells may need one more replica to handle a possible failover, while still maintaining the same replica serving capacity. * 
----------------------------------------

Document 2:
  Source: Unknown
  Score: 0.7915507555007935
  Content:
----------------------------------------
with the number `1` are performed concurrently. Here we can see that Phase 1 and 2 are initiated across all the shards for the multi-sharded insert concurrently. It is only in Phase 3 when we start doing the commits to each of the shards in serial, which allows us to abandon or roll back changes to at least a subset of the shards if something goes wrong between the `2 ks1/40-80: commit` and the `5 ks1/-40: commit`. ### Method 4: The TWOPC way Vitess also supports (assuming the vtgate and vttablets have been configured appropriately) a two-phase commit option for multi-shard writes. This is enabled by using the non-default setting for `transaction_mode` of **TWOPC**. In this mode, Vitess can guarantee atomicity for cross-shard writes; but still does not guarantee isolation; i.e. other clients can still see partial commits across shards. It should be emphasized that if you need to use **TWOPC** extensively in your application, you may be using Vitess incorrectly; the vast majority of Vitess users do not use it at all. See our [TWOPC page](../../../reference/features/distributed-transaction/) for more details on how to configure **TWOPC**. In TWOPC mode, Vitess uses the `_vt` sidecar database to record metadata related to each transactions across multiple tables. As a result, any multi-shard write in **TWOPC** mode is likely to be an order of a magnitude slower than in **MULTI** mode. Unfortunately, we cannot use `vtexplain` to illustrate the working of TWOPC mode. ## In closing From the above examples, it should be clear that as the number of shards increase, large write operations that span multiple shards become more problematic from a performance point of view. It is therefore important for Vitess keyspaces (databases) that will span a large number of shards to be designed in a way that individual writes will affect a minimum of shards. --- title: File based authentication weight: 2 --- The simplest way to configure users is using a `static` auth method, and we can define the users in a JSON formatted file or string. ```sh $ cat > users.json << EOF { "vitess": [ { "UserData": "vitess", "Password": "supersecretpassword" } ], "myuser1": [ { "UserData": "myuser1", "Password": "password1" } ], "myuser2": [ { "UserData": "myuser2", "Password": "password2" } ] } EOF ``` Then we can load this into VTGate with the additional commandline parameters: ```sh vtgate $(cat <<END_OF_COMMAND --mysql_auth_server_impl=static --mysql_auth_server_static_file=users.json ... ... ... END_OF_COMMAND ) ``` Now we can test our new users: ``` $ mysql -h 127.0.0.1 -u myuser1 -ppassword1 -e "select 1" +---+ | 1 | +---+ | 1 | +---+ $ mysql -h 127.0.0.1 -u myuser1 -pincorrect_password -e "select 1" ERROR 1045 (28000): Access denied for user 'myuser1' ``` ## Password format In the above example we used plaintext passwords. Vitess supports the MySQL [mysql_native_password](https://dev.mysql.com/doc/refman/8.0/en/native-pluggable-authentication.html) hash format, and you should always specify your passwords using this in a non-test or external environment. Vitess does not support the full [caching_sha2_password](https://dev.mysql.com/doc/refman/8.0/en/caching-sha2-pluggable-authentication.html) authentication cycle, it is only supported through ssl. To use a `mysql_native_password` hash, your user 
----------------------------------------

Document 3:
  Source: Unknown
  Score: 0.7018632888793945
  Content:
----------------------------------------
see partial commits while a TwoPC transaction commit is in progress. The current implementation prioritizes performance for common use cases. Full ACID isolation across shards would introduce significant performance overhead. ## Configuration ### VTGate Set the default transaction mode via the `transaction_mode` flag: ```bash # Default mode (multi-shard, best-effort) transaction_mode=multi # Force single-shard transactions transaction_mode=single # Enable TwoPC by default transaction_mode=twopc ``` Override the default mode for specific sessions: ```sql SET transaction_mode='twopc'; ``` ### VTTablet Enable TwoPC on VTTablet with these flags: ```bash # Enable TwoPC support --twopc_enable # Time in seconds before marking transaction as abandoned # Recommended: 5-10 minutes --twopc_abandon_age=300 ``` Transaction watcher at VTTablet uses `twopc_abandon_age` to count the pending abandoned transaction and sends signal to VTGate for resolution. ### MySQL Prerequisites 1. **Semi-sync Replication** - Required for atomic commit guarantees - TwoPC transactions will roll back if semi-sync is not enabled 2. **Connection Timeout** - Verify `wait_timeout` is set appropriately (default: 28800 seconds) - Short timeouts risk premature connection closure during prepared transactions ## Monitoring Users can monitor distributed transactions at a per-transaction level with `SHOW STATEMENT` and at a higher level with metrics. When a commit failure is received from VTGate on the session, a `show warnings` statement can be issued to retrieve the Distributed transaction ID (DTID). This DTID can be tracked to monitor the state of the transaction. The `SHOW TRANSACTION STATUS FOR <DTID>` statement can be used to retrieve the status of the transaction. Example: ```mysql > show transaction status for <dtid>; +-------------+---------+-------------------------------+-------------------+ | id | state | record_time | participants | +-------------+---------+-------------------------------+-------------------+ | ks:-80:4334 | PREPARE | 2024-07-06 04:05:34 +0000 UTC | ks:80-a0,ks:a0-c0 | +-------------+---------+-------------------------------+-------------------+ 1 row in set (0.00 sec) ``` Additional metrics have been added for monitoring the distributed transactions. ### VTGate * **CommitModeTimings**: This is a histogram that shows the time taken to commit transactions in different transaction modes. * **CommitUnresolved**: This is a counter that shows the number of commits that were not concluded by VTGate after a commit decision was made. * **QueriesRouted**: This is a counter with PlanType (Commit) as a dimension to track the number of shards involved in a transaction. ### VTTablet * **QueryTimings**: This is a histogram that shows the time taken to perform an operation. It can be used to track TwoPC commit operations such as **CreateTransaction**, **Prepare**, **StartCommit**, **SetRollback**, **CommitPrepared**, **RollbackPrepared** and **Resolve**. * **Unresolved**: This is a gauge that shows the number of unresolved transactions that have been lingering longer than the abandon age. #### Critical Failures The following errors are not expected to happen. If they do, it means that TwoPC transactions have failed to commit atomically: * **InternalErrors.TwopcOpen**: This is a counter that tracks the number of failures the TwoPC engine is unable to open. Any unresolved prepared transactions will remain abandoned. * **InternalErrors.TwopcCommit**: This is a counter that tracks the number of failures to fulfill a commit request on the prepared transactions. * **InternalErrors.TwopcPrepareRedo**: This is a counter that tracks the number of failures to re-prepare 
----------------------------------------

Document 4:
  Source: Unknown
  Score: 0.655724048614502
  Content:
----------------------------------------
by a single user. The username is passed to vttablet from vtgate. If you are using a limited set of users, you may want to increase this limit. Or disable this limit feature by setting `--transaction_limit_by_username` to `false` as the default is `true`. This option only comes into play if the TX limiter is enabled by `--enable_transaction_limit`, which it is not by default. ### vtgate system settings Flag: `--enable_system_settings` This vtgate flag allows clients to modify a [subset of system settings](https://github.com/vitessio/vitess/blob/main/go/vt/sysvars/sysvars.go#L174-L217) on the MySQL. ## Calculating maximum db connections used by vttablet You can use the following formula to approximate the maximum MySQL connections per vttablet instance: ``` --queryserver-config-transaction-cap x 2 (transaction_pool and found_rows_pool) + --queryserver-config-pool-size (conn_pool) + --queryserver-config-stream-pool-size (stream_conn_pool) + --dba_pool_size (dba_conn_pool) + --app_pool_size (app_conn_pool) + 3 (tx_read_pool, hardcoded) + 7 (online DDL) + variable (on demand: for vreplication, MySQL replication, etc; should < 10) + variable (reserved connections used by `enable_system_settings`) ``` {{< info >}} Note that most servers will not use this many connections, since most workloads do not exercise all the pools. {{< /info >}} --- title: Distributed Transactions weight: 11 aliases: ['/docs/launching/twopc/','/docs/reference/two-phase-commit/','/docs/reference/distributed-transaction/'] --- # Distributed Transactions in Vitess ## Overview A distributed transaction is an operation that spans multiple database shards while maintaining data consistency. Vitess supports distributed transactions through a Two-Phase Commit (TwoPC) protocol, allowing you to perform atomic updates across different shards in your database cluster. > **Performance Note:** Using atomic distributed transactions will impact commit latency. > We recommend designing your VSchema to minimize cross-shard updates where possible. ## Transaction Modes Vitess supports three levels of transaction atomicity, each offering different guarantees and performance characteristics: | Mode | Description | Use Case | Guarantees | |------|-------------|----------|-----------| | Single | Transactions limited to one shard | Simple CRUD operations | Full ACID | | Multi | Can span multiple shards with best-effort commits | Bulk updates where partial success is acceptable | No atomicity | | TwoPC | Atomic commits across multiple shards | Financial transactions, inventory updates | Atomic commits | ### When to Use TwoPC Choose TwoPC when you need guaranteed atomic commits across shards, such as: - Financial transactions where partial commits could lead to inconsistent balances - Inventory systems where items must be updated together - Other user transactions that modify data across multiple shards or keyspaces that must remain consistent. ## Understanding Isolation Levels While TwoPC guarantees atomicity (all-or-nothing commits), it does not provide isolation in the traditional ACID sense. Applications might observe fractured reads in a cross-shard query i.e. a query might see partial commits while a TwoPC transaction commit is in progress. The current implementation prioritizes performance for common use cases. Full ACID isolation across shards would introduce significant performance overhead. ## Configuration ### VTGate Set the default transaction mode via the `transaction_mode` flag: ```bash # Default mode (multi-shard, best-effort) transaction_mode=multi # Force single-shard transactions transaction_mode=single # Enable TwoPC by default transaction_mode=twopc ``` Override the default mode for specific sessions: ```sql SET transaction_mode='twopc'; ``` ### VTTablet 
----------------------------------------

