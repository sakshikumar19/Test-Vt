DETAILED QUERY LOG - 2025-03-16 20:23:36
======================================================================

QUESTION: What is the significance of semi-sync replication in Vitess, and how does it enhance durability and high availability?

ANSWER: ### Significance of Semi-Sync Replication in Vitess
Semi-sync replication is a crucial component in Vitess, enhancing durability and high availability in the following ways:

#### Durability
* **Prevents split brain**: Semi-sync replication prevents split brain scenarios by ensuring that all replicas have stopped replicating before a new primary is elected. This guarantees that the old primary is not accepting writes, even if it cannot be contacted.
* **Guarantees transaction consistency**: With semi-sync replication, Vitess ensures that at least one replica has every transaction that was ever reported to clients as having completed. This guarantee is strengthened in MySQL 5.7+ to prevent loss of any transactions that were ever committed on the original primary.

#### High Availability
* **Survives primary failure**: Semi-sync replication allows Vitess to survive sudden primary failure without losing any transactions that were reported to clients as completed. This is achieved by waiting for VTOrc to repair the cluster or manually promoting the replica that is farthest ahead in GTID position to be the new primary.
* **Ensures data consistency**: Semi-sync replication ensures that data is consistent across all replicas, which is critical for maintaining high availability and preventing data inconsistencies.

#### Configuration
* **Unlimited semi-sync timeout**: Vitess configures the semi-sync timeout to be essentially unlimited, ensuring that it will never fall back to asynchronous replication. This prevents split brain scenarios and ensures that the cluster remains consistent.
* **Restrictions on rdonly tablets**: Vitess does not allow rdonly tablets to send semi-sync ACKs, as they are not eligible to be promoted to primary. This prevents scenarios where a rdonly tablet is the single best candidate for election at the time of primary failure.

In summary, semi-sync replication is a critical component in Vitess, providing strong guarantees for durability and high availability. It ensures that transactions are consistent across all replicas, prevents split brain scenarios, and allows the cluster to survive primary failure without losing any transactions.

METRICS:
  - Documents Retrieved: 4
  - Top Document Score: 0.9738962650299072
  - Response Time: 14898.4 ms

RETRIEVED DOCUMENTS:
Document 1:
  Source: Unknown
  Score: 0.9738962650299072
  Content:
----------------------------------------
Vitess plans * You can use a special `SELECT` query to see the next value from a sequence: ```sql select next value from user_seq; ``` --- title: Replication weight: 9 aliases: ['/docs/reference/row-based-replication/','/docs/reference/vitess-replication/','/docs/reference/mysql-replication/'] --- {{< warning >}} Vitess requires the use of Row-Based Replication with GTIDs enabled. In addition, Vitess only supports the default `binlog_row_image` of `FULL`. {{< /warning >}} Vitess makes use of MySQL Replication for both high availability and to receive a feed of changes to database tables. This feed is then used in features such as [VReplication](../../vreplication/vreplication/), and to identify schema changes so that caches can be updated. ## Semi-Sync Vitess strongly recommends the use of Semi-synchronous replication for High Availability. The characteristics of semi-sync are replication governed by the [Durability Policy](../../../user-guides/configuration-basic/durability_policy) configured for the keyspace. Some characteristics are shared by all the policies - * Vitess configures the semi-sync timeout to essentially an unlimited number so that it will never fallback to asyncronous replication. This is important to prevent split brain (or alternate futures) in case of a network partition. If we can verify all replicas have stopped replicating, we know the old primary is not accepting writes, even if we are unable to contact the old primary itself. * All pre-configured durability policies do not allow tablets of type rdonly to send semi-sync ACKs. This is intentional because rdonly tablets are not eligible to be promoted to primary, so Vitess avoids the case where a rdonly tablet is the single best candidate for election at the time of primary failure. Having semi-sync enabled, gives you the property that, in case of primary failure, there is at least one other replica that has every transaction that was ever reported to clients as having completed. You can then wait for [VTOrc](../../../user-guides/configuration-basic/vtorc) to repair it, or ([manually](../../programs/vtctl/shards/#emergencyreparentshard) pick the replica that is farthest ahead in GTID position and promote that to be the new primary. Thus, you can survive sudden primary failure without losing any transactions that were reported to clients as completed. In MySQL 5.7+, this guarantee is strengthened slightly to preventing loss of any transactions that were ever **committed** on the original primary, eliminating so-called [phantom reads](http://bugs.mysql.com/bug.php?id=62174). On the other hand these behaviors also give a requirement that each shard must have at least 2 tablets with type *replica* (with addition of the primary that can be demoted to type *replica* this gives a minimum of 3 tablets with initial type *replica*). This will allow for the primary to have a semi-sync acker when one of the replica tablets is down for any reason (for a version update, machine reboot, or anything else). These requirements will changed based on the durability policy. With regard to replication lag, note that this does **not** guarantee there is always at least one replica from which queries will always return up-to-date results. Semi-sync guarantees that at least one replica has the transaction in its relay log, but it has not necessarily been applied yet. The only way Vitess guarantees a fully 
----------------------------------------

Document 2:
  Source: Unknown
  Score: 0.9519549608230591
  Content:
----------------------------------------
a given VTTablet you will need to perform the following steps: 1. Create the new user in the database. 2. Give that user the required permissions. The list of what Vitess requires can be found [here](https://github.com/vitessio/vitess/blob/master/config/init_db.sql). 3. Then when you start up Vitess you need to pass in the username and passwords to Vitess. That is done by setting `--db_user` and `--db-credentials-file`. The credentials file will have the format: ```sh { "<user name>": [ "<password>" ] } ``` After you have followed the above steps the credentials file will tell VTTablet the account to use to connect to the database. You can read additional details on the credentials file format [here](https://github.com/vitessio/vitess/blob/master/examples/local/mysql_auth_server_static_creds.json). ## If mysqld replication thread isn't running what restarts it? VTOrc will automatically restart replication if it is not running. ## What is semi-sync replication? Semi-sync replication enables you to prevent your primary from acknowledging a transaction to the client until a replica confirms that it has received all the changes. This adds an extra guarantee that at least one other machine has a copy of the changes. This addresses the problem of a combination of lagging replication and network issues resulting in data loss. With semi-sync replication, even if you have network issues you shouldnâ€™t lose your data. Please do note that when using semi-sync replication you will have to wait for your data to flow from the primary to the replica and then get a confirmation back to the primary. Thus each transaction may take longer. The length of time depends on the round trip time from the primary to the replica. ## Why would I use semi-sync replication? Semi-sync replication ensures data durability between the primary and at least one replica. Hardware failures are unavoidable but don't need to result in data loss if you run with semi-sync replication. --- title: Advanced Configuration docs_nav_disable_expand: true weight: 10 --- --- title: Compatibility weight: 2 --- ## What versions of MySQL or MariaDB work with Vitess? Please refer to our [Supported Databases](https://vitess.io/docs/overview/supported-databases/) for the most up-to-date information. ## What does it mean to say that Vitess "is MySQL compatible"? Will my application "just work"? Vitess supports much of MySQL, with some limitations. **Depending on your MySQL setup you will need to adjust queries that utilize any of the current unsupported cases.** For SQL syntax there is a list of example [unsupported queries](https://github.com/vitessio/vitess/blob/main/go/vt/vtgate/planbuilder/testdata/unsupported_cases.json). There are some further [compatibility issues](https://vitess.io/docs/reference/mysql-compatibility/) beyond pure SQL syntax. ## How is Vitess different from MySQL? MySQL is a popular open source database solution. MySQL delivers a fast, multi-threaded, multi-user, and robust SQL (Structured Query Language) database server. However, MySQL starts running into limitations with large data sizes or large numbers of concurrent users. Vitess is a database scaling system designed to be used with MySQL. It enables deploying, scaling and managing large clusters of MySQL instances with built-in sharding, high availability and connection pooling. ## How is Vitess different from RDS for MySQL? RDS for MySQL is a managed service from AWS which has 
----------------------------------------

Document 3:
  Source: Unknown
  Score: 0.9438984990119934
  Content:
----------------------------------------
hurdle is crossed. There are fewer lock contentions to worry about, replication is a lot happier, production impact of outages is smaller, backups and restores run faster, and a lot more secondary advantages can be realized. For example, you can shuffle instances around to get better machine or rack diversity leading to even smaller production impact on outages, and improved resource usage. ## Durability through replication Traditional data storage software treated data as durable as soon as it was flushed to disk. However, this approach is impractical in todayâ€™s world of commodity hardware. Such an approach also does not address disaster scenarios. The new approach to durability is achieved by copying the data to multiple machines, and even geographical locations. This form of durability addresses the modern concerns of device failures and disasters. Many of the workflows in Vitess have been built with this approach in mind. For example, turning on semi-sync replication is highly recommended. This allows Vitess to failover to a new replica when a primary goes down, with no data loss. Vitess also recommends that you avoid recovering a crashed database. Instead, create a fresh one from a recent backup and let it catch up. Relying on replication also allows you to loosen some of the disk-based durability settings. For example, you can turn off `sync_binlog`, which greatly reduces the number of IOPS to the disk thereby increasing effective throughput. ## Consistency model Before sharding or moving tables to different keyspaces, the application needs to be verified (or changed) such that it can tolerate the following changes: * Cross-shard reads may not be consistent with each other. Conversely, the sharding decision should also attempt to minimize such occurrences because cross-shard reads are more expensive. * In "best-effort mode", cross-shard transactions can fail in the middle and result in partial commits. You could instead use "2PC mode" transactions that give you distributed atomic guarantees. However, choosing this option increases the write cost by approximately 50%. Single shard transactions continue to remain ACID, just like MySQL supports it. If there are read-only code paths that can tolerate slightly stale data, the queries should be sent to REPLICA tablets for OLTP, and RDONLY tablets for OLAP workloads. This allows you to scale your read traffic more easily, and gives you the ability to distribute them geographically. This trade-off allows for better throughput at the expense of stale or possibly inconsistent reads, since the reads may be lagging behind the primary, as data changes (and possibly with varying lag on different shards). To mitigate this, VTGate servers are capable of monitoring replica lag and can be configured to avoid serving data from instances that are lagging beyond X seconds. For a true snapshot, queries must be sent to the primary within a transaction. For read-after-write consistency, reading from the primary without a transaction is sufficient. To summarize, these are the various levels of consistency supported: * `REPLICA/RDONLY` read: Servers can be scaled geographically. Local reads are fast, but can be stale 
----------------------------------------

Document 4:
  Source: Unknown
  Score: 0.8776386380195618
  Content:
----------------------------------------
any reason (for a version update, machine reboot, or anything else). These requirements will changed based on the durability policy. With regard to replication lag, note that this does **not** guarantee there is always at least one replica from which queries will always return up-to-date results. Semi-sync guarantees that at least one replica has the transaction in its relay log, but it has not necessarily been applied yet. The only way Vitess guarantees a fully up-to-date read is to send the request to the primary. ## MySQL Replication Modes Vitess requires the use of [Row-Based Replication (RBR)](https://dev.mysql.com/doc/refman/en/replication-formats.html) with [GTIDs](https://dev.mysql.com/doc/refman/en/replication-gtids.html) enabled: [`--binlog-row-format=ROW`](https://dev.mysql.com/doc/refman/en/replication-options-binary-log.html#sysvar_binlog_format) and [`--gtid-mode=ON`](https://dev.mysql.com/doc/refman/en/replication-options-gtids.html#sysvar_gtid_mode). Vitess also recommends [`FULL`](https://dev.mysql.com/doc/refman/en/replication-options-binary-log.html#sysvar_binlog_row_image) binary log images in order to support all manner of transformations in [VReplication workflows](../../vreplication/vreplication/), but in v17 we added *experimental* support for [`--binlog-row-image=NOBLOB`](https://dev.mysql.com/doc/refman/en/replication-options-binary-log.html#sysvar_binlog_row_image) (see [#1290](https://github.com/vitessio/vitess/pull/12905) for more details). Vitess v22 and later fully supports the usage of [`--binlog-row-value-options=PARTIAL_JSON`](https://dev.mysql.com/doc/refman/en/replication-options-binary-log.html#sysvar_binlog_row_value_options) with MySQL 8.0 and later. ## Database Schema Considerations * Row-based replication requires that replicas have the same schema as the primary, and corruption will likely occur if the column order does not match. * Using a column of type `FLOAT` or `DOUBLE` as part of a Primary Key is not supported. This limitation is because Vitess may try to execute a query for a value (for example 2.2) which MySQL will return zero results, even when the approximate value is present. * It is not recommended to change the schema at the same time a resharding operation is being performed. This limitation exists because interpreting RBR events requires accurate knowledge of the table's schema, and Vitess does not always correctly handle the case that the schema has changed. --- title: Point In Time Recovery weight: 17 aliases: ['/docs/recovery/pitr','/docs/reference/pitr/'] --- ## Point in Time Recovery Vitess supports incremental backup and recoveries, AKA point in time recoveries. It supports both restore-to-timestamp and (one second resolution) as well as restore-to-position (precise GTID set). Point in time recoveries are based on full and incremental backups. It is possible to recover a database to a position that is _covered_ by some backup. See [Backup Types](../../../user-guides/operating-vitess/backup-and-restore/overview/#backup-types) and [Restore Types](../../../user-guides/operating-vitess/backup-and-restore/overview/#restore-types) for an overview of incremental backups and restores. See the user guides for how to [Create an Incremental Backup](../../../user-guides/operating-vitess/backup-and-restore/creating-a-backup/#create-an-incremental-backup-with-vtctl) and how to [Restore to a position](../../../user-guides/operating-vitess/backup-and-restore/bootstrap-and-restore/#restore-to-a-point-in-time). ### Supported Databases - 8.0 --- title: Schema Management weight: 16 aliases: ['/docs/schema-management/','/docs/user-guides/schema-management/','/docs/reference/schema-management/'] --- Using Vitess requires you to work with two different types of schemas: 1. The MySQL database schema. This is the schema of the individual MySQL instances. 2. The [VSchema](../vschema), which describes all the keyspaces and how they're sharded. The workflow for the `VSchema` is as follows: 1. Apply the `VSchema` for each keyspace using the `ApplyVschema` command. This saves the VSchemas in the global topology service. 2. Execute `RebuildVSchemaGraph` for each cell (or all cells). This command propagates a denormalized version of the combined VSchema to all the specified cells. The main purpose for this propagation is to minimize the dependency of each cell from the global topology. The ability to 
----------------------------------------

