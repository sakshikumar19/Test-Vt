DETAILED QUERY LOG - 2025-03-15 22:39:17
======================================================================

QUESTION: How do I inform Vitess of a new primary tablet after a manual failover?

ANSWER: ### Informing Vitess of a New Primary Tablet After Manual Failover
To inform Vitess of a new primary tablet after a manual failover, you can use the `TabletExternallyReparented` command. This command tells Vitess which tablet corresponds to the new primary MySQL.

Until you run this command, writes will fail because they will be routed to a read-only replica (the old primary). 

Alternatively, you can use tools like [Orchestrator](https://github.com/github/orchestrator), which can be configured to call this automatically when a failover occurs.

METRICS:
  - Documents Retrieved: 4
  - Top Document Score: 0.9991499185562134
  - Response Time: 15747.25 ms

RETRIEVED DOCUMENTS:
Document 1:
  Source: Unknown
  Score: 0.9991499185562134
  Content:
----------------------------------------
you need to do planned maintenance on the primary, it's best to first reparent to another replica with [`PlannedReparentShard`](../../reference/programs/vtctl/shards/#plannedreparentshard). --- title: Vitess sees the wrong tablet as primary description: Debug common issues with Vitess weight: 10 --- ## Vitess sees the wrong tablet as primary If you do a failover manually (not through Vitess), you'll need to tell Vitess which tablet corresponds to the new primary MySQL. Until then, writes will fail since they'll be routed to a read-only replica (the old primary). Use the [`TabletExternallyReparented`](../../reference/programs/vtctl/shards/#tabletexternallyreparented) command to tell Vitess the new primary tablet for a shard. Older versions of Vitess supported tools like [Orchestrator](https://github.com/github/orchestrator), which can be configured to call this automatically when a failover occurs. See our sample [orchestrator.conf.json](https://github.com/vitessio/vitess/blob/1129d69282bb738c94b8af661b984b6377a759f7/docker/orchestrator/orchestrator.conf.json#L131) for an example of this. --- title: Troubleshoot aliases: ['/docs/launching/troubleshooting/'] description: Debug common issues with Vitess weight: 2600 --- If there is a problem in the system, one or many alerts would typically fire. If a problem was found through means other than an alert, then the alert system needs to be iterated upon. When an alert fires, you have the following sources of information to perform your investigation: * Alert values * Graphs * Diagnostic URLs * Log files ### Find version of Vitess build ``` select @@version; ```
----------------------------------------

Document 2:
  Source: Unknown
  Score: 0.9670777320861816
  Content:
----------------------------------------
the stream and follows it to completion. The new primary must be available within `10 minutes`, or else the migration is considered to be stale and is aborted. ## Auto retry after failure Vitess management can issue an automated retry (starting the migration afresh). - which `vttablet` initiated the migration - how many times a migration has been retried - whether a migration failed due to a `vttablet` failure (as is the case in a failover scenario) Vitess will auto-retry a failed migration when: - The migration failed due to a `vttablet` failure, and - it has not been retried (this is a temporary restriction) The migration will be transitioned into `queued` state, as if the user requested a `retry` operation. Note that this takes place on a per-shard basis. The primary use case is a primary failure and failover. The newly promoted tablet will be able to retry the migration that broke during the previous primary failure. To clarify, the migration will start anew, as at this time there is no mechanism to resume a broken migration. ## Throttling `vitess` utilizes the tablet throttler, which is a cooperative throttler service based on replication lag. The tablet throttler automatically detects topology `REPLICA` tablets and adapts to changes in the topology. See [Tablet throttler](../../../reference/features/tablet-throttler/). **NOTE** that at this time (and subject to change) the tablet throttler is disabled by default. Enable it via `vtctldclient UpdateThrottlerConfig --enable <keyspace>`. If the tablet throttler is disabled, schema migrations will not throttle on replication lag. ## Table cleanup All `ALTER` strategies leave artifacts behind. Whether successful or failed, either the original table or the _ghost_ table is left still populated at the end of the migration. Vitess explicitly makes sure the tables are not dropped at the end of the migration. This is for two reasons: - Make the table/data still available for a while, and - In MySQL prior to `8.0.23`, a `DROP TABLE` operation can be dangerous in production as it commonly locks the buffer pool for a substantial period. The tables are kept for 24 hours after migration completion. Vitess automatically cleans up those tables as soon as a migration completes (either successful or failed). You will normally not need to do anything. Artifact tables are identifiable via `artifacts` column in a `SHOW VITESS_MIGRATION ...` command. You should generally not touch these tables. It's possible to `DROP` those tables with `direct` DDL strategy. Note that dropping tables in production can be risky and lock down your database for a substantial period of time. Dropping artifact tables also makes the migrations impossible to [revert](../revertible-migrations/). ## Noblob The `noblob` binlog row image is supported by the MoveTables and Reshard VReplication workflows. **NOTE** replication does not support blobs as part of the `PRIMARY KEY` in `MoveTables` operations, or as part of the [migration key](../../../reference/vreplication/internal/keys/) in Online DDL operations. --- title: Postponed migrations weight: 12 aliases: ['/docs/user-guides/schema-changes/postponed-migrations/'] --- Postponed migrations allow: - Postponing the launch of a migration, and/or - Postponing the final cut-over/completion of a 
----------------------------------------

Document 3:
  Source: Unknown
  Score: 0.7473552823066711
  Content:
----------------------------------------
from other parts of the system where Vitess components will be launched. --- title: Initialize Shard Primary weight: 9 --- A new primary is elected automatically by VTOrc and no user action is required. The InitShardPrimary command can be used to do the same operation manually. However, it is a destructive command and should only be used by advanced users. This command copies over the `executed_gtid_set` from the primary to the replica which can break replication if the user isn't careful. The command for `InitShardPrimary` is as follows: ```text vtctldclient \ InitShardPrimary \ --force \ commerce/0 \ cell1-100 ``` Until this step is complete, you may see errors like this in the vttablet logs: `Cannot start query service: Unknown database 'vt_xxx'`. This is because the database will be created only after a primary is elected. If you have semi-sync enabled and did not set up at least two replicas, InitShardPrimary could hang indefinitely. Even if it succeeds, future operations that perform failovers could cause this shard to go into a deadlocked state. After this step, visiting the `/debug/status` page on the vttablets should show all the tablets as healthy: ![healthy-tablet](../img/healthy-tablet.png) {{< warning >}} `InitShardPrimary` is a destructive command that resets all servers by deleting their binlog metadata. It should only be used for initializing a brand new cluster. {{< /warning >}} {{< info >}} `InitShardPrimary` is deprecated. This action is performed automatically by VTOrc. If manual action is needed, it is recommended to use `PlannedReparentShard`. {{< /info >}} --- title: Keyspaces and Shards weight: 7 --- You can create keyspaces and shards using [vtctldclient](../../../reference/programs/vtctldclient) commands. However, they are not necessary because these are implicitly created as you bring up the vttablets. The canonical information for keyspaces and shards is initially created in the global topo. This information is then deployed to the cell-specific topos through rebuild commands like `RebuildKeyspaceGraph` and `RebuildVSchemaGraph`. These commands are implicitly issued on your behalf whenever applicable. But there are situations where you will have to issue them manually. For example, if you create a new cell, you will have to issue these commands to copy the data into the new cell. There are use cases where you may want to experimentally deploy changes to only some cells. Separating information from the global topo and local cells makes those experiments possible without affecting the entire deployment. Tools like [vtgate](../../../reference/programs/vtgate) and [vttablet](../../../reference/programs/vttablet) consume information from the local copy of the topo. An unsharded keyspace typically has a single shard named `0` or` -`. A sharded keyspace has shards named after the keyranges assigned to it, like `-80` and `80-`. Please refer to the section on [shard naming](../../../concepts/shard/#shard-naming) for more info on how shards are named. --- title: Monitoring weight: 16 aliases: ['/docs/launching/server-configuration/', '/docs/user-guides/server-configuration/', '/docs/user-guides/configuring-components/'] --- This section describes how to monitor Vitess components. Additionally, we recommend that you also add the necessary monitoring and alerting for the TopoServers as well as the MySQL instances running with each vttablet. ## Tools Vitess provides integrations with a variety of 
----------------------------------------

Document 4:
  Source: Unknown
  Score: 0.6856129169464111
  Content:
----------------------------------------
for tables [corder,customer] will be updated Switch writes completed, freeze and delete vreplication streams on: [tablet:200] Start reverse vreplication streams on: [tablet:101] Mark vreplication streams frozen on: [keyspace:customer;shard:0;tablet:200;workflow:commerce2customer;dbname:vt_customer] Unlock keyspace customer Unlock keyspace commerce ``` --- title: Migration description: User guides covering data migrations into Vitess weight: 3 --- --- title: Upgrading Vitess weight: 1 aliases: ['/docs/user-guides/upgrading/', '/docs/user-guides/upgrading-vitess/'] --- This document highlights things to be aware of when upgrading a Vitess production installation to a newer Vitess release. Generally speaking, upgrading Vitess is a safe and easy process because it is explicitly designed for it. This is because at YouTube we followed the practice of releasing new versions often (usually from the tip of the Git primary branch). ## Compatibility Our versioning strategy is based on [Semantic Versioning](http://semver.org/). Vitess version numbers follow the format `MAJOR.MINOR.PATCH`. We guarantee compatibility when upgrading to a newer **patch** or **minor** version. Upgrades to a higher **major** version may require manual configuration changes. In general, always **read the 'Upgrading' section of the release notes**. It will mention any incompatible changes and necessary manual steps. ## Upgrade Order We recommend upgrading Vitess using a bottom up approach starting with the vttablet instances and ending with application updates. Upgrades and restarts for vttablets should be handled one at a time, in a rotating fashion, with the primary tablet being last. All components will need restarts after applying upgrades. Please use this upgrade order (unless otherwise noted in the release notes): * vttablet * vtctld * vtgate * application code which links client libraries ## Canary Testing Within the vtgate and vttablet components, we recommend to [canary](http://martinfowler.com/bliki/CanaryRelease.html) single instances, keyspaces and cells. Upgraded canary instances can "bake" for several hours or days to verify that the upgrade did not introduce a regression. Eventually, you can upgrade the remaining instances. ## Rolling Upgrades We recommend to automate the upgrade process with a configuration management software. It will reduce the possibility of human errors and simplify the process of managing all instances. As of June 2016 we do not have templates for any major open-source configuration management software because our internal upgrade process is based on a proprietary software. Therefore, we invite open-source users to contribute such templates. Any upgrade should be a rolling release i.e. usually one tablet at a time within a shard. This ensures that the remaining tablets continue serving live traffic and there is no interruption. ## Upgrading the Primary Tablet The *primary* tablet of each shard should always be updated last in the following manner: * verify that all *replica* tablets in the shard have been upgraded * reparent away from the current *primary* to a *replica* tablet * upgrade old *primary* tablet --- title: Operational description: User guides covering operational aspects of Vitess weight: 5 skip_sections: true --- --- title: Backups and Restore for Local Environment weight: 5 aliases: ['/docs/user-guides/backup-and-restore/'] --- {{< info >}} This guide follows on from the Get Started guides. Please make sure that you have a [local](../../../../get-started/local) installation ready. It 
----------------------------------------

